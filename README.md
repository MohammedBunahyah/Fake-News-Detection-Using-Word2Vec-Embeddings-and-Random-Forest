# ğŸš€ Fake News Detection Using Word2Vec Embeddings and Random Forest

This project builds a **Fake News Detector** using **Word2Vec embeddings** for text representation combined with a **Random Forest** classifier. It also explores text analysis techniques like **sentiment analysis**, **word clouds**, and **model comparison**.

---

## ğŸ“š Project Overview

- âœ… Load and clean a dataset of real and fake news articles
- âœ‚ï¸ Preprocess text: lowercasing, stopword removal, lemmatization
- ğŸ§  Train a **Word2Vec** model to embed words into vectors
- ğŸ”  Represent entire articles by averaging word vectors
- ğŸŒ³ Train a **Random Forest** model for fake news classification
- ğŸ“ˆ Evaluate model performance with classification metrics
- ğŸ”® Predict labels for unseen validation data
- ğŸ“Š Visualize most common words and generate word clouds
- ğŸ˜ Analyze sentiment distribution across real and fake articles
- âš¡ Compare different models (Random Forest, Logistic Regression, SVM)

---

## ğŸ› ï¸ Tech Stack

| Component               | Tool/Library                     |
|--------------------------|----------------------------------|
| Text Preprocessing       | `nltk`, `re`, `WordNetLemmatizer` |
| Word Embeddings          | `gensim` Word2Vec                |
| Classification Models    | `Random Forest`, `Logistic Regression`, `SVM` |
| Visualization            | `matplotlib`, `seaborn`, `wordcloud` |
| Sentiment Analysis       | `nltk` Vader                     |
| Environment              | Jupyter / Colab                  |

---

## ğŸ§ª How It Works

1. ğŸ“‚ Load the news dataset (`data.csv`) and validation set (`validation_data.csv`)
2. ğŸ§¹ Clean and preprocess articles for cleaner model input
3. ğŸ§  Train a **Word2Vec** model on the training data
4. ğŸ”  Represent articles by averaging their word embeddings
5. ğŸŒ³ Train a **Random Forest** classifier using document vectors
6. ğŸ“ˆ Evaluate using accuracy, precision, recall, F1-score
7. ğŸ”® Predict fake/real labels for new validation articles
8. ğŸ“Š Analyze common words and visualize data using word clouds
9. ğŸ† Compare multiple models: Random Forest, Logistic Regression, and SVM

---

## ğŸ’» Notebook Contents

- `Fake_News_Detection_Word2Vec.ipynb`
  - [x] Data loading and cleaning
  - [x] Word2Vec training and embedding generation
  - [x] Random Forest training and evaluation
  - [x] Validation set prediction
  - [x] Sentiment analysis
  - [x] Word frequency and word cloud visualization
  - [x] Model benchmarking (Random Forest, Logistic Regression, SVM)

---

## ğŸ§  Sample Results

| Model                  | Accuracy  |
|-------------------------|-----------|
| Random Forest           | ~95%      |
| Logistic Regression     | ~94%      |
| SVM                     | ~93%      |

- ğŸ¯ **Word2Vec + Random Forest** achieved the best performance.
- ğŸ“° **Real News** tends to have slightly more neutral sentiment compared to **Fake News**.

---

## âš ï¸ Known Issues / Limitations

- âŒ Word2Vec averaging loses word order and context
- ğŸ” Sentiment analysis using Vader is basic; could be enhanced with a fine-tuned LLM
- ğŸ“ Model may struggle with very short or ambiguous headlines

---

## ğŸ“ˆ Improvements & Next Steps

- ğŸ§  Try fine-tuned transformer models (e.g., DistilBERT, RoBERTa) for better embeddings
- ğŸ·ï¸ Include metadata like news source, publication date
- ğŸ” Perform Named Entity Recognition (NER) for claim verification
- ğŸš€ Build a full interactive web app using **Streamlit** (bonus)

---

## ğŸš€ Try It Yourself

Install the required libraries first:
```bash
pip install nltk scikit-learn gensim matplotlib seaborn wordcloud
```

Download NLTK resources:
```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('vader_lexicon')
```

Then simply run the notebook step by step!

---

âœ… **READY!**  
This README is fully aligned to your favorite format. ğŸ”¥  

---

**Quick extras if you want:**
- I can give you a `.gitignore` template (to ignore models, vectorizers, etc.)
- Or suggest a clean project folder layout (`/models`, `/data`, `/notebooks`, `/scripts`, etc.)

Just say the word! ğŸš€  
And when you send the next `.ipynb`, I'm ready! ğŸ¯

## Datasets can be found here
https://drive.google.com/drive/folders/1040eGEOM_LXIM14P2-VFZEk2pjDBfDh5?usp=sharing
